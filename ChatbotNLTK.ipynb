{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import nltk\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "f = open('Act1Scene1.txt', 'r', errors='ignore')\n",
    "raw = f.read()\n",
    "raw = raw.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(raw) #converts to list of scentences\n",
    "word_tokens = nltk.word_tokenize(raw) #converts to list of words\n",
    "\n",
    "sentToken = sent_tokens[:4]\n",
    "#print(sentToken)\n",
    "wordToken = word_tokens[:4]\n",
    "#print(wordToken)\n",
    "\n",
    "#preprocessing \n",
    "lemmer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(stop_words='english', tokenizer=['what', 'are', 'you', 'doing'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "TfidfVectorizer(tokenizer=LemNormalize('what are you doing'), stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "#Greetings\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"nods\", \"hi there\", \"hello\", \"I am glad! you are talking to me\"]\n",
    "\n",
    "def greeting(scentence):\n",
    "    \n",
    "    for word in scentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def response(user_response):\n",
    "    chatbot_response = ''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=\"english\")\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    # print (tfidf, tfidf[-1])\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf == 0):\n",
    "        chatbot_response = chatbot_response + \"I am sorry! I don't understand you\"\n",
    "        return chatbot_response\n",
    "    \n",
    "    else:\n",
    "        chatbot_response=chatbot_response+sent_tokens[idx]\n",
    "        return chatbot_response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, there my name is Aneka. I will answer your queries. If you want to exit, type Bye!\n",
      "**********\n",
      "Type here: Rebellious subjects\n",
      "DS35_Chatbot:(enter prince, with attendants)\n",
      "\n",
      "prince\n",
      "rebellious subjects, enemies to peace,\n",
      "profaners of this neighbour-stained steel,â€”\n",
      "will they not hear?\n",
      "**********\n",
      "Type here: Cast by their grave beseeming ornaments\n",
      "DS35_Chatbot:three civil brawls, bred of an airy word,\n",
      "by thee, old capulet, and montague,\n",
      "have thrice disturb'd the quiet of our streets,\n",
      "and made verona's ancient citizens\n",
      "cast by their grave beseeming ornaments,\n",
      "to wield old partisans, in hands as old,\n",
      "canker'd with peace, to part your canker'd hate:\n",
      "if ever you disturb our streets again,\n",
      "your lives shall pay the forfeit of the peace.\n",
      "**********\n",
      "Type here: Here were the servants\n",
      "DS35_Chatbot:benvolio\n",
      "here were the servants of your adversary,\n",
      "and yours, close fighting ere i did approach:\n",
      "i drew to part them: in the instant came\n",
      "the fiery tybalt, with his sword prepared,\n",
      "which, as he breathed defiance to my ears,\n",
      "he swung about his head and cut the winds,\n",
      "who nothing hurt withal hiss'd him in scorn:\n",
      "while we were interchanging thrusts and blows,\n",
      "came more and more and fought on part and part,\n",
      "till the prince came, who parted either part.\n",
      "**********\n",
      "Type here: thank you\n",
      "DS35_Chatbot: You're welcome!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    flag = True\n",
    "    print(\"Hello, there my name is Aneka. I will answer your queries. If you want to exit, type Bye!\")\n",
    "    while(flag==True):\n",
    "        print ('**********')\n",
    "        user_response = input(\"Type here: \")\n",
    "        user_response = user_response.lower()\n",
    "        if(user_response!='bye'):\n",
    "            if user_response == 'thanks' or user_response == 'thank you':\n",
    "                flag = False\n",
    "                print(\"DS35_Chatbot: You're welcome!\")\n",
    "            else:\n",
    "                if(greeting(user_response)!=None):\n",
    "                    print(\"\\n DS35_Chatbot:\" +greeting(user_response))\n",
    "                else:\n",
    "                    print(\"DS35_Chatbot:\", end='')\n",
    "                    print(response(user_response))\n",
    "                    sent_tokens.remove(user_response)\n",
    "        else:\n",
    "            flag = False\n",
    "            print(\"Aneka: Bye! Have a great time!\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6ca0fa7ce7bbb0a79954fd344190fa79005e3baa6147c7762ef10e98302bd8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
